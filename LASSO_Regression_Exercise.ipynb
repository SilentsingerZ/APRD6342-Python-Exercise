{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct  3 20:27:43 2018\n",
    "\n",
    "@author: Freddie\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "\n",
    "# load data and preview\n",
    "df = pd.read_csv('finalmaster-ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 190 variables in this dataset. One outcome variable \"# Purchases\" and 189 possible predictors.\n",
    "# First, I want you to create a list of all the predictors you're going to feed into the LassoLarsCV model. \n",
    "allvariablenames = list(df.columns.values)\n",
    "\n",
    "# For the sake of this homework, we know that the first 8 variables aren't valid predictors of what we're interested in. \n",
    "listofallpredictors = allvariablenames[8:]\n",
    "#load predictors into dataframe\n",
    "predictors = df[listofallpredictors]  \n",
    "\n",
    "#load target into dataframe\n",
    "target = df['# Purchases']   \n",
    "\n",
    "# split data into train and test sets, with 30% retained for test\n",
    "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123)    \n",
    "\n",
    "# Fitting\n",
    "model = LassoLarsCV(precompute=False, cv=10)\n",
    "model.fit(pred_train, tar_train)\n",
    "\n",
    "# create a new table called predictors_model that loading all predictors name from listofallpredictors.\n",
    "predictors_model = pd.DataFrame(listofallpredictors)\n",
    "\n",
    "# rename the column name of predictors_model to 'label'.\n",
    "predictors_model.columns = ['label']\n",
    "\n",
    "# add a new column called 'coeff' and append all coefficents from regression model.\n",
    "predictors_model['coeff'] = model.coef_\n",
    "\n",
    "# for loop that go through predictor_model table and print out the coefficent with name that larger than zero.   \n",
    "for index, row in predictors_model.iterrows():\n",
    "    if row['coeff'] > 0:\n",
    "        print(row.values)\n",
    "     \n",
    "# Question 1: Comment in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2:\n",
    "# ['B01001014' 0.8557908775529921] Males aged 40 to 44 Years.\n",
    "# If there is one more Males aged 40 to 44 Years, we will sell 0. 8557908775529921 unit more Bobo Bars.\n",
    "\n",
    "# ['B01001036' 2.505392496591849] Females aged 30 to 34 Years.\n",
    "# If there is one more Females aged 30 to 34 Years, we will sell 2.505392496591849 unit more Bobo Bars.\n",
    "        \n",
    "# ['B01001037' 0.8894214357013622] Females aged 35 to 39 Years.\n",
    "# If there is one more Females aged 35 to 39 Years, we will sell 0.8894214357013622 unit more Bobo Bars.\n",
    "\n",
    "# ['B01001038' 1.5315839680821497] Females aged 40 to 44 Years.\n",
    "# If there is one more Females aged 40 to 44 Years, we will sell 1.5315839680821497 unit more Bobo Bars.\n",
    "        \n",
    "# ['B02001005' 0.4125408937426837] Asian Alone\n",
    "# If there is one more Asian Alone, we will sell 0.4125408937426837 unit more Bobo Bars.\n",
    "        \n",
    "# ['B13014026' 0.4800240326923769] Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Bachelor's Degree\n",
    "# If there is one more Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Bachelor's Degree, we will sell 0.4800240326923769 unit more Bobo Bars.\n",
    "\n",
    "# ['B13014027' 0.6977454940063235] Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Graduate or Professional Degree\n",
    "# If there is one more Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Graduate or Professional Degree, we will sell 0.6977454940063235 unit more Bobo Bars.\n",
    "\n",
    "# ['B13016001' 874922971.7249781] Women 15 to 50 Years Who Had a Birth in the Past 12 Months\n",
    "# If there is one more Women 15 to 50 Years Who Had a Birth in the Past 12 Months, we will sell 874922971.7249781 unit more Bobo Bars.\n",
    "\n",
    "# ['B19001017' 1.4834465563617387] Household with income $200,000 or More.\n",
    "# If there is one more Household with income $200,000 or More, we will sell 1.4834465563617387 unit more Bobo Bars.\n",
    "\n",
    "# Question 3:\n",
    "# If I had to report only two census variables to my boss that most steeply predicted sales, the first one would be \n",
    "# Women 15 to 50 Years Who Had a Birth in the Past 12 Months and the second one would be Females aged 30 to 34 Years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error \n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
    "print ('training data MSE')\n",
    "print(train_error)\n",
    "\n",
    "test_error = mean_squared_error(tar_test, model.predict(pred_test))\n",
    "print ('testing data MSE')\n",
    "print(test_error)\n",
    "        \n",
    "# Question 4:    \n",
    "# The mean squared error for training data is 22025.312777378716 and for testing data is 41549.12573000182, \n",
    "# which are not similar. The mean squared error is the measurement of how close a fitted line is to the \n",
    "# data points. The smaller MSE is, the closer the fits is to the data. Since the model is regressed by training\n",
    "# data, the MSE for training data has a less value, which means fitting better, than testing data, make a lot of sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r squared\n",
    "rsquared_train = model.score(pred_train, tar_train)\n",
    "print ('training data R-square')\n",
    "print(rsquared_train)\n",
    "\n",
    "rsquared_test = model.score(pred_test, tar_test)\n",
    "print ('testing data R-square')\n",
    "print(rsquared_test)\n",
    "\n",
    "# The R-squared for training data is 0.24002827375880997 and the R-squared for testing data is \n",
    "# 0.17587122769388464. Through comparing the R-squared value, we could know that the training \n",
    "# data set has a better regression model as it has a larger R-squared value.\n",
    "\n",
    "# Question 5: \n",
    "# If your boss asked, \"How well does Census data, overall, predict sales?\" What would you say? Why?\n",
    "# I would say Census data is not a good fit of predicting sales amount. Even though training data would show\n",
    "# a better fit than the actual testing data, the MSE for training data set is still a bit large and \n",
    "# the R-squared value of training data set is too small to make a good prediction. In both training date\n",
    "# set and the testing data set, the MSE and R-squared value are not sufficient enough to make prediction\n",
    "# about the sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y interecept:\")\n",
    "print(model.intercept_)\n",
    "# Question 6: \n",
    "# What is our baseline sales number? What does that mean, practically? Think back to what y-intercepts mean in regression models.\n",
    "# According to the intercept, the baseline sales number is 22.194697684317433. Practically, it means when value of every\n",
    "# variable is 0, no 40 to 44 years old women or anything, there are 22.194697684317433 Bobo bars will be sold."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
